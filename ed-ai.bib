@article{Ali2023,
  title = {Supporting Self-Directed Learning and Self-Assessment Using {{TeacherGAIA}}, a Generative {{AI}} Chatbot Application: {{Learning}} Approaches and Prompt Engineering},
  shorttitle = {Supporting Self-Directed Learning and Self-Assessment Using {{TeacherGAIA}}, a Generative {{AI}} Chatbot Application},
  author = {Ali, Farhan and Choy, Doris and Divaharan, Shanti and Tay, Hui Yong and Chen, Wenli},
  date = {2023-07-03},
  journaltitle = {Learning: Research and Practice},
  shortjournal = {Learning: Research and Practice},
  volume = {9},
  number = {2},
  pages = {135--147},
  issn = {2373-5082, 2373-5090},
  doi = {10.1080/23735082.2023.2258886},
  url = {https://www.tandfonline.com/doi/full/10.1080/23735082.2023.2258886},
  urldate = {2025-09-25},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/EA2YQ69T/Ali et al. - 2023 - Supporting self-directed learning and self-assessment using TeacherGAIA, a generative AI chatbot app.pdf}
}

@article{Bloom1984,
  title = {The 2 {{Sigma Problem}}: {{The Search}} for {{Methods}} of {{Group Instruction}} as {{Effective}} as {{One-to-One Tutoring}}},
  shorttitle = {The 2 {{Sigma Problem}}},
  author = {Bloom, Benjamin S.},
  date = {1984-06},
  journaltitle = {Educational Researcher},
  shortjournal = {Educational Researcher},
  volume = {13},
  number = {6},
  pages = {4--16},
  issn = {0013-189X, 1935-102X},
  doi = {10.3102/0013189X013006004},
  url = {https://journals.sagepub.com/doi/10.3102/0013189X013006004},
  urldate = {2025-05-18},
  langid = {english},
  keywords = {category-psychology,important,mcp-research,review-needed,source-semantic_scholar},
  file = {/Users/francojc/Zotero/storage/GVARH55C/Bloom - 1984 - The 2 Sigma Problem The Search for Methods of Group Instruction as Effective as One-to-One Tutoring.pdf}
}

@article{Chamot2004,
  title = {Issues in Language Learning Strategy Research and Teaching},
  author = {Chamot, Anna Uhl},
  date = {2004},
  journaltitle = {Electronic journal of foreign language teaching},
  volume = {1},
  number = {1},
  pages = {14--26},
  url = {http://e-flt.nus.edu.sg/v1n12004/chamot.pdf.http://e-flt.nus.edu.sg/v1n12004/chamot.pdf},
  urldate = {2025-06-27},
  file = {/Users/francojc/Zotero/storage/I4MS45T2/Chamot - 2004 - Issues in language learning strategy research and teaching.pdf}
}

@article{Chen,
  title = {{{WIP}}: {{Large Language Model-Enhanced Smart Tutor}} for {{Undergraduate Circuit Analysis}}},
  author = {Chen, Liangliang and Xie, Huiru and Rohde, Jacqueline and Zhang, Ying},
  abstract = {This research-to-practice work-in-progress (WIP) paper presents an AI-enabled smart tutor designed to provide homework assessment and feedback for students in an undergraduate circuit analysis course. We detail the tutor’s design philosophy and core components, including open-ended question answering and homework feedback generation. The prompts are carefully crafted to optimize responses across different problems. The smart tutor was deployed on the Microsoft Azure platform and is currently in use in an undergraduate circuit analysis course at the School of Electrical and Computer Engineering in a large, public, research-intensive institution in the Southeastern United States. Beyond offering personalized instruction and feedback, the tutor collects student interaction data, which is summarized and shared with the course instructor. To evaluate its effectiveness, we collected student feedback, with 90.9\% of responses indicating satisfaction with the tutor. Additionally, we analyze a subset of collected data on preliminary circuit analysis topics to assess tutor usage frequency for each problem and identify frequently asked questions. These insights help instructors gain real-time awareness of student difficulties, enabling more targeted classroom instruction. In future work, we will release a full analysis once the complete dataset is available after the Spring 2025 semester. We also explore the potential applications of this smart tutor across a broader range of engineering disciplines by developing improved prompts, diagram-recognition methods, and database management strategies, which remain ongoing areas of research.},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/5QTECIMW/Chen et al. - WIP Large Language Model-Enhanced Smart Tutor for Undergraduate Circuit Analysis.pdf}
}

@article{Collentine2010,
  title = {A {{Corpus-Based Analysis}} of the {{Discourse Functions}} of\enspace{{Ser}}/{{Estar}}\enspace + {{Adjective}} in {{Three Levels}} of {{Spanish}} as {{FL Learners}}},
  author = {Collentine, Joe and Asención-Delaney, Yuly},
  date = {2010},
  journaltitle = {Language Learning},
  volume = {60},
  number = {2},
  pages = {409--445},
  issn = {00238333},
  doi = {10.1111/j.1467-9922.2010.00563.x},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9922.2010.00563.x/full},
  abstract = {Research on the acquisition of Spanish's two copulas,serandestar, provides an understanding of the interaction among syntax, semantics, pragmatics, morphology, and vocabulary during development (e.g., Geeslin, 2003a, 2003b; Gunterman, 1992; Ryan \& Lafford, 1992). Recent research suggests that linguistic features in the surrounding discourse influence learners copula choice. We present a corpus-based analysis of the lexico-grammatical features co-occurring with copula + adjective usage among foreign-language learners of Spanish at three levels of instruction. Findings revealed the following: (a) bothser+ adjective andestar+ adjective occur at all levels where little linguistic complexity typically occurs; (b)ser+ adjective appears in descriptive and evaluative discourse; and (c)estar+ adjective is present in narrations, descriptions, and hypothetical discourse.},
  file = {/Users/francojc/Zotero/storage/B4NEIMMD/Collentine and Asención-Delaney - 2010 - A Corpus-Based Analysis of the Discourse Functions of SerEstar + Adjective in Three Levels of Spani.pdf}
}

@article{Cruz,
  title = {{{WIP}}: {{STRUCTURED AI TUTORING IN ENGINEERING EDUCATION}}},
  author = {Cruz, Alberto C and Yatawara, Anjana and Misha, Maruti and Wang, Jianjun and Highway, Stockdale},
  abstract = {This innovative practice Work-in-Progress paper presents a structured approach to integrating AI tutors into undergraduate engineering education at a Hispanic-Serving Institution. The study focuses on two upper-division computer architecture courses and explores how large language models (LLMs), such as ChatGPT-4o, can be scaffolded to support student learning. Our approach emphasizes guided AI interaction rather than direct answer generation. It is grounded in Vygotsky’s Zone of Proximal Development and implemented through the ADDIE instructional design model. Two scaffolding protocols—AI Think-Aloud and AI-Driven Pair Programming—are proposed, that foster metacognitive engagement and collaborative problem-solving. The paper highlights the need for differentiated instruction aligned with Universal Design for Learning (UDL) to assist individuals who lack skills necessary to take advantage of LLMs. Preliminary findings suggest that structured AI integration can enhance learning outcomes and engagement, while minimizing risks associated with unregulated AI use. Evaluation methods include SOLO taxonomy analysis of student-AI interactions and short-term longitudinal survey data on student attitudes. The work contributes to emerging frameworks for ethical, inclusive, and pedagogically grounded AI adoption in engineering classrooms.},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/NJBUNXKJ/Cruz et al. - WIP STRUCTURED AI TUTORING IN ENGINEERING EDUCATION.pdf}
}

@online{Dong2025,
  title = {How to {{Build}} an {{Adaptive AI Tutor}} for {{Any Course Using Knowledge Graph-Enhanced Retrieval-Augmented Generation}} ({{KG-RAG}})},
  author = {Dong, Chenxi and Yuan, Yimin and Chen, Kan and Cheng, Shupei and Wen, Chujie},
  date = {2025-02-12},
  eprint = {2311.17696},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.17696},
  url = {http://arxiv.org/abs/2311.17696},
  urldate = {2025-04-14},
  abstract = {Integrating Large Language Models (LLMs) in Intelligent Tutoring Systems (ITS) presents transformative opportunities for personalized education. However, current implementations face two critical challenges: maintaining factual accuracy and delivering coherent, context-aware instruction. While Retrieval-Augmented Generation (RAG) partially addresses these issues, its reliance on pure semantic similarity limits its effectiveness in educational contexts where conceptual relationships are crucial. This paper introduces Knowledge Graph-enhanced Retrieval-Augmented Generation (KG-RAG), a novel framework that integrates structured knowledge representation with context-aware retrieval to enable more effective AI tutoring. We present three key contributions: (1) a novel architecture that grounds AI responses in structured domain knowledge, (2) empirical validation through controlled experiments (n=76) demonstrating significant learning improvements (35\% increase in assessment scores, p{$<$}0.001), and (3) a comprehensive implementation framework addressing practical deployment considerations. These results establish KG-RAG as a robust solution for developing adaptable AI tutoring systems across diverse educational contexts.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/francojc/Zotero/storage/8W7QJRZW/Dong et al. - 2025 - How to Build an Adaptive AI Tutor for Any Course Using Knowledge Graph-Enhanced Retrieval-Augmented.pdf;/Users/francojc/Zotero/storage/HZCGRK9T/2311.html}
}

@online{Ekin2023,
  title = {Prompt {{Engineering For ChatGPT}}: {{A Quick Guide To Techniques}}, {{Tips}}, {{And Best Practices}}},
  shorttitle = {Prompt {{Engineering For ChatGPT}}},
  author = {Ekin, Sabit},
  date = {2023-04-29},
  doi = {10.36227/techrxiv.22683919.v1},
  url = {https://www.techrxiv.org/doi/full/10.36227/techrxiv.22683919.v1},
  urldate = {2025-11-05},
  abstract = {This innovative practice WIP paper describes the development and effectiveness of an AI-powered chatbot designed to support undergraduate computer science students in learning C++ through guided explanations rather than direct solutions. Unlike traditional AI tutoring systems, this chatbot fosters active engagement by prompting structured problem-solving. The study investigates how students interact with the chatbot, the impact on comprehension, and implementation challenges. A preliminary deployment was conducted using the Rasa framework and GPTbased models in a C++ course, collecting interaction logs, survey results, and interviews. Early findings suggest that students appreciate structured guidance and show improved conceptual understanding, although some struggle with the lack of direct answers. Future work includes refining the chatbot’s Natural Language Processing (NLP) capabilities, incorporating adaptive learning, and conducting comparative evaluations using Vertex AI.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/francojc/Zotero/storage/XWEZRBSW/Ekin - 2023 - Prompt Engineering For ChatGPT A Quick Guide To Techniques, Tips, And Best Practices.pdf}
}

@article{Federiakin2024,
  title = {Prompt Engineering as a New 21st Century Skill},
  author = {Federiakin, Denis and Molerov, Dimitri and Zlatkin-Troitschanskaia, Olga and Maur, Andreas},
  date = {2024-11-29},
  journaltitle = {Frontiers in Education},
  shortjournal = {Front. Educ.},
  volume = {9},
  pages = {1366434},
  issn = {2504-284X},
  doi = {10.3389/feduc.2024.1366434},
  url = {https://www.frontiersin.org/articles/10.3389/feduc.2024.1366434/full},
  urldate = {2025-09-25},
  abstract = {Artificial Intelligence (AI) promises to revolutionize nearly every aspect of human learning. However, users have observed that the efficacy of AI assistants hinges crucially on the quality of the prompts supplied to them. A slight alteration in wording can make the difference between an assistant misinterpreting an instruction and exceeding expectations. The skill of precisely communicating the essence of a problem to an AI assistant is as crucial as the assistant itself. This paper aims to introduce Prompt Engineering (PE) as an emerging skill essential for personal and professional learning and development in the 21st century. We define PE as the skill of articulating a problem, its context, and the constraints of the desired solution to an AI assistant, ensuring a swift and accurate response. We show that no existing related frameworks on 21st skills and others cover PE to the extent that allows for its valid assessment and targeted promotion in school and university education. Thus, we propose a conceptual framework for this skill set including (1) comprehension of the basic prompt structure, (2) prompt literacy, (3) the method of prompting, and (4) critical online reasoning. We also discuss the implications and challenges for the assessment framework of this skill set and highlight current PE-related recommendations for researchers and educators.},
  file = {/Users/francojc/Zotero/storage/HXIKDJHR/Federiakin et al. - 2024 - Prompt engineering as a new 21st century skill.pdf}
}

@article{Fragakis2025,
  title = {Empowering {{Education}} with {{Intelligent Systems}}: {{Exploring Large Language Models}} and the {{NAO Robot}} for {{Information Retrieval}}},
  shorttitle = {Empowering {{Education}} with {{Intelligent Systems}}},
  author = {Fragakis, Nikos and Trichopoulos, Georgios and Caridakis, George},
  date = {2025-01},
  journaltitle = {Electronics},
  volume = {14},
  number = {6},
  pages = {1210},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics14061210},
  url = {https://www.mdpi.com/2079-9292/14/6/1210},
  urldate = {2025-04-14},
  abstract = {To unlock more aspects of human cognitive structuring, human–AI and human–robot interactions require increasingly advanced communication skills on both the human and robot sides. This paper compares three methods of retrieving cultural heritage information in primary school education: search engines, large language models (LLMs), and the NAO humanoid robot, which serves as a facilitator with programmed answering capabilities for convergent questions. Human–robot interaction has become a critical aspect of modern education, with robots like the NAO providing new opportunities for engaging and personalized learning experiences. The NAO, with its anthropomorphic design and ability to interact with students, presents a unique approach to fostering deeper connections with educational content, particularly in the context of cultural heritage. The paper includes an introduction, extensive literature review, methodology, research results from student questionnaires, and conclusions. The findings highlight the potential of intelligent and embodied technologies for enhancing knowledge retrieval and engagement, demonstrating the NAO’s ability to adapt to student needs and facilitate more dynamic learning interactions.},
  issue = {6},
  langid = {english},
  keywords = {education,intelligent systems,LLM,NAO robot,search engines},
  file = {/Users/francojc/Zotero/storage/XRBLQ2PT/Fragakis et al. - 2025 - Empowering Education with Intelligent Systems Exploring Large Language Models and the NAO Robot for.pdf}
}

@online{Gao2024,
  title = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
  date = {2024-03-27},
  eprint = {2312.10997},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.10997},
  url = {http://arxiv.org/abs/2312.10997},
  urldate = {2025-05-28},
  abstract = {Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/francojc/Zotero/storage/TFPU54W6/Gao et al. - 2024 - Retrieval-Augmented Generation for Large Language Models A Survey.pdf;/Users/francojc/Zotero/storage/R7A9KT4H/2312.html}
}

@article{Gomes,
  title = {{{ChatGPT}} as a {{Teaching Assistant}} in a {{CS1}} Course: {{An Experience Report}}},
  author = {Gomes, Luiza N and Fraga, Camila F and Holanda, Maristela and Silva, Dilma Da},
  abstract = {This innovative practice full paper presents the findings of an experiment conducted in an introductory programming course (CS1) at the University of Brası´lia, Brazil, comparing the effectiveness of undergraduate teaching assistants and ChatGPT. CS1 is often a challenging course for students, typically supported by multiple teaching assistants. With the growing use of generative artificial intelligence (AI) in education, particularly chatbot tools like ChatGPT and Gemini, virtual assistants are playing an increasingly prominent role in programming instruction, even during face-to-face lab sessions. The experiment involved 41 undergraduate students over three consecutive weeks, with one 80-minute session per week. The students were divided into two groups: one supported by human teaching assistants and the other assisted by ChatGPT. Participants were grouped to balance prior computer science experience and demographic factors. After each lab session, students completed a survey and their submitted work was assessed for accuracy. Additionally, exam scores and students’ perceptions of the learning experience were analyzed to evaluate the impact of each method on performance and engagement. The findings showed that students assisted by ChatGPT completed more assignments in less time, with submission accuracy comparable to that of the control group. While students acknowledged the helpfulness of ChatGPT, many still preferred human assistance. This study adds to the growing body of literature on AI in education, which highlights generative AI’s ability to support tasks such as coding, debugging, and concept clarification. However, few studies have directly compared AI assistance to human support in classroom settings. These findings provide valuable insights into the potential of generative AI tools like ChatGPT to complement or even replace traditional teaching methods in programming education.},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/45RXFUCV/Gomes et al. - ChatGPT as a Teaching Assistant in a CS1 course An Experience Report.pdf}
}

@article{Guskey2007,
  title = {Closing {{Achievement Gaps}}: {{Revisiting Benjamin S}}. {{Bloom}}'s “{{Learning}} for {{Mastery}}”},
  shorttitle = {Closing {{Achievement Gaps}}},
  author = {Guskey, Thomas R.},
  date = {2007-11},
  journaltitle = {Journal of Advanced Academics},
  shortjournal = {Journal of Advanced Academics},
  volume = {19},
  number = {1},
  pages = {8--31},
  issn = {1932-202X, 2162-9536},
  doi = {10.4219/jaa-2007-704},
  url = {https://journals.sagepub.com/doi/10.4219/jaa-2007-704},
  urldate = {2025-06-18},
  abstract = {The problem of achievement gaps among different subgroups of students has been evident in education for many years. This manuscript revisits the work of renowned educator Benjamin S. Bloom, who saw reducing gaps in the achievement of various groups of students as a simple problem of reducing variation in student learning outcomes. Bloom observed that teaching all students in the same way and giving all the same time to learn—that is, providing little variation in the instruction—typically results in great variation in student learning. Students for whom the instructional methods and amount of time are appropriate learn well, and those for whom the methods and time are less appropriate learn less well. Bloom believed that all students could be helped to reach a high criterion of learning if both the instructional methods and time were varied to better match students' individual learning needs. In other words, to reduce variation in the achievement of diverse groups of students and have all students learn well, Bloom argued that educators and teachers must increase variation in instructional approaches and learning time. Bloom labeled the strategy to accomplish this instructional variation and differentiation mastery learning. Research evidence shows that the positive effects of mastery learning are not limited to cognitive or achievement outcomes. The process also yields improvements in students' confidence in learning situations, school attendance rates, involvement in class sessions, attitudes toward learning, and a variety of other affective measures.},
  langid = {english},
  keywords = {bloom,mastery learning},
  file = {/Users/francojc/Zotero/storage/36GA4ZKP/Guskey - 2007 - Closing Achievement Gaps Revisiting Benjamin S. Bloom's “Learning for Mastery”.pdf}
}

@article{Kahl2024,
  title = {Enhancing {{AI Tutoring}} in {{Robotics Education}}:{{Evaluating}} the {{Effect}} of {{Retrieval- Augmented Generation}} and {{Fine-Tuning}} on {{Large Language Models}}},
  author = {Kahl, Sebastian and Löffler, Felix and Maciol, Martin and Ridder, Fabian and Schmitz, Marius and Spanagel, Jennifer and Wienkamp, Jens and Schilling, Malte},
  date = {2024},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/P47DLD9K/Kahl et al. - 2024 - Enhancing AI Tutoring in Robotics EducationEvaluating the Effect of Retrieval- Augmented Generation.pdf}
}

@article{Klingner1996,
  title = {Reciprocal {{Teaching}} of {{Reading Comprehension Strategies}} for {{Students}} with {{Learning Disabilities Who Use English}} as a {{Second Language}}},
  author = {Klingner, Janette Kettmann and Vaughn, Sharon},
  date = {1996-01},
  journaltitle = {The Elementary School Journal},
  shortjournal = {The Elementary School Journal},
  volume = {96},
  number = {3},
  pages = {275--293},
  issn = {0013-5984, 1554-8279},
  doi = {10.1086/461828},
  url = {https://www.journals.uchicago.edu/doi/10.1086/461828},
  urldate = {2025-09-25},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/MFATZAJU/Klingner and Vaughn - 1996 - Reciprocal Teaching of Reading Comprehension Strategies for Students with Learning Disabilities Who.pdf}
}

@article{Kularbphettong2015,
  title = {Developing an {{Adaptive Web-based Intelligent Tutoring System Using Mastery Learning Technique}}},
  author = {Kularbphettong, Kunyanuth and Kedsiribut, Pubet and Roonrakwit, Pattarapan},
  date = {2015-06},
  journaltitle = {Procedia - Social and Behavioral Sciences},
  shortjournal = {Procedia - Social and Behavioral Sciences},
  volume = {191},
  pages = {686--691},
  issn = {18770428},
  doi = {10.1016/j.sbspro.2015.04.619},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1877042815028797},
  urldate = {2025-06-18},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/B9YF6HP4/Kularbphettong et al. - 2015 - Developing an Adaptive Web-based Intelligent Tutoring System Using Mastery Learning Technique.pdf}
}

@article{Kulik2016,
  title = {Effectiveness of {{Intelligent Tutoring Systems}}: {{A Meta-Analytic Review}}},
  shorttitle = {Effectiveness of {{Intelligent Tutoring Systems}}},
  author = {Kulik, James A. and Fletcher, J. D.},
  date = {2016-03},
  journaltitle = {Review of Educational Research},
  shortjournal = {Review of Educational Research},
  volume = {86},
  number = {1},
  pages = {42--78},
  issn = {0034-6543, 1935-1046},
  doi = {10.3102/0034654315581420},
  url = {https://journals.sagepub.com/doi/10.3102/0034654315581420},
  urldate = {2025-06-27},
  abstract = {This review describes a meta-analysis of findings from 50 controlled evaluations of intelligent computer tutoring systems. The median effect of intelligent tutoring in the 50 evaluations was to raise test scores 0.66 standard deviations over conventional levels, or from the 50th to the 75th percentile. However, the amount of improvement found in an evaluation depended to a great extent on whether improvement was measured on locally developed or standardized tests, suggesting that alignment of test and instructional objectives is a critical determinant of evaluation results. The review also describes findings from two groups of evaluations that did not meet all of the selection requirements for the meta-analysis: six evaluations with nonconventional control groups and four with flawed implementations of intelligent tutoring systems. Intelligent tutoring effects in these evaluations were small, suggesting that evaluation results are also affected by the nature of control treatments and the adequacy of program implementations.},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/K9TCW5ZH/Kulik and Fletcher - 2016 - Effectiveness of Intelligent Tutoring Systems A Meta-Analytic Review.pdf}
}

@inproceedings{Kwon2024,
  title = {{{BIPED}}: {{Pedagogically Informed Tutoring System}} for {{ESL Education}}},
  shorttitle = {{{BIPED}}},
  booktitle = {Proceedings of the 62nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Kwon, Soonwoo and Kim, Sojung and Park, Minju and Lee, Seunghyun and Kim, Kyuseok},
  editor = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
  date = {2024-08},
  pages = {3389--3414},
  publisher = {Association for Computational Linguistics},
  location = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.acl-long.186},
  url = {https://aclanthology.org/2024.acl-long.186/},
  urldate = {2025-04-29},
  abstract = {Large Language Models (LLMs) have a great potential to serve as readily available and cost-efficient Conversational Intelligent Tutoring Systems (CITS) for teaching L2 learners of English. Existing CITS, however, are designed to teach only simple concepts or lack the pedagogical depth necessary to address diverse learning strategies. To develop a more pedagogically informed CITS capable of teaching complex concepts, we construct a BIlingual PEDagogically-informed Tutoring Dataset (BIPED) of one-on-one, human-to-human English tutoring interactions. Through post-hoc analysis of the tutoring interactions, we come up with a lexicon of dialogue acts (34 tutor acts and 9 student acts), which we use to further annotate the collected dataset. Based on a two-step framework of first predicting the appropriate tutor act then generating the corresponding response, we implemented two CITS models using GPT-4 and SOLAR-KO, respectively. We experimentally demonstrate that the implemented models not only replicate the style of human teachers but also employ diverse and contextually appropriate pedagogical strategies.},
  eventtitle = {{{ACL}} 2024},
  keywords = {annotation,dialog acts,ITS,pedagogy},
  file = {/Users/francojc/Zotero/storage/S5MH2WKU/Kwon et al. - 2024 - BIPED Pedagogically Informed Tutoring System for ESL Education.pdf}
}

@article{Lee2025,
  title = {Prompt Engineering in Higher Education: A Systematic Review to Help Inform Curricula},
  shorttitle = {Prompt Engineering in Higher Education},
  author = {Lee, Daniel and Palmer, Edward},
  date = {2025-02-10},
  journaltitle = {International Journal of Educational Technology in Higher Education},
  shortjournal = {Int J Educ Technol High Educ},
  volume = {22},
  number = {1},
  pages = {7},
  issn = {2365-9440},
  doi = {10.1186/s41239-025-00503-7},
  url = {https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-025-00503-7},
  urldate = {2025-09-25},
  abstract = {This paper presents a systematic review of the role of prompt engineering during interactions with Generative Artificial Intelligence (GenAI) in Higher Education (HE) to discover potential methods of improving educational outcomes. Drawing on a comprehensive search of academic databases and relevant literature, key trends, including multiple framework designs, are presented and explored to review the role, relevance, and applicability of prompt engineering to purposefully improve GenAI-generated responses in higher education contexts. Multiple experiments using a variety of prompt engineering frameworks are compared, contrasted and discussed. Analysis reveals that well-designed prompts have the potential to transform interactions with GenAI in higher education teaching and learning. Further findings show it is important to develop and teach pragmatic skills in AI interaction, including meaningful prompt engineering, which is best managed through a well-designed framework for creating and evaluating GenAI applications that are aligned with pre-determined contextual educational goals. The paper outlines some of the key concepts and frameworks that educators should be aware of when incorporating GenAI and prompt engineering into their teaching practices, and when teaching students the necessary skills for successful GenAI interaction.},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/PYWDD92F/Lee and Palmer - 2025 - Prompt engineering in higher education a systematic review to help inform curricula.pdf}
}

@article{Mizumoto2023,
  title = {Exploring the Potential of Using an {{AI}} Language Model for Automated Essay Scoring},
  author = {Mizumoto, Atsushi and Eguchi, Masaki},
  date = {2023-08},
  journaltitle = {Research Methods in Applied Linguistics},
  shortjournal = {Research Methods in Applied Linguistics},
  volume = {2},
  number = {2},
  pages = {100050},
  issn = {27727661},
  doi = {10.1016/j.rmal.2023.100050},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2772766123000101},
  urldate = {2025-06-26},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/H6LCZS29/Mizumoto and Eguchi - 2023 - Exploring the potential of using an AI language model for automated essay scoring.pdf}
}

@article{Momdjian2024,
  title = {Enhancing {{English Reading Comprehension}} of {{ESL Underachievers}} by {{Fostering Metacognitive Strategies}}},
  author = {Momdjian, Loussine and Chidiac, Fady El},
  date = {2024-01-01},
  journaltitle = {Theory and Practice in Language Studies},
  shortjournal = {tpls},
  volume = {14},
  number = {1},
  pages = {21--30},
  issn = {2053-0692, 1799-2591},
  doi = {10.17507/tpls.1401.03},
  url = {https://tpls.academypublication.com/index.php/tpls/article/view/7216},
  urldate = {2025-09-25},
  abstract = {This study investigates the efficacy of implementing metacognitive reading strategies in English classes to enhance the reading comprehension of underachieving Arab second-language learners. The research included a specifically developed lesson in three sixth-grade classes at a Saudi girls' school and a control group of three additional classrooms. Information was gathered through pre-and post-tests, interviews, and observations. The results reveal that students taught metacognitive skills caught up to their more successful classmates regarding reading comprehension. The implications of these methods for English as a Second Language (ESL) instruction are examined. These findings provide valuable insights into the capacity of metacognitive reading strategies to close the comprehension gap among underachieving ESL learners in the Arab context. Based on the findings, the research recommends incorporating these methods into English classes as an effective way to improve student's reading comprehension and overall performance in the classroom.},
  file = {/Users/francojc/Zotero/storage/QJYI4UDT/Momdjian and Chidiac - 2024 - Enhancing English Reading Comprehension of ESL Underachievers by Fostering Metacognitive Strategies.pdf}
}

@article{Moreno2023,
  title = {Experimental Evaluation of {{Large Language Models}} for In-Class Learning Experience Customization},
  author = {Moreno, Daniel and Guerra, Victor and Ravelo-Garcıa, Antonio G},
  date = {2023},
  abstract = {This paper explores the utilization of Large Language Models (LLMs) for personalized education in Secondary Education, focusing on motivation and personalization. It uses the GPT 3.5 model by OpenAI to generate tailored exercises and examines their impact on student motivation and academic performance. The study highlights the positive correlation between motivation and performance, emphasizing the need to consider classroom dynamics and teacher-student relationships. While LLMs enhance educational content, they should complement, not replace, the teacher’s role. The research calls for further investigation into personalization’s impact on education, considering study duration and student samples for a more robust understanding.},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/JRKF7VJ3/Moreno et al. - 2023 - Experimental evaluation of Large Language Models for in-class learning experience customization.pdf}
}

@article{Mzwri2025,
  title = {The {{Impact}} of {{Prompt Engineering}} and a {{Generative AI-Driven Tool}} on {{Autonomous Learning}}: {{A Case Study}}},
  shorttitle = {The {{Impact}} of {{Prompt Engineering}} and a {{Generative AI-Driven Tool}} on {{Autonomous Learning}}},
  author = {Mzwri, Kovan and Turcsányi-Szabo, Márta},
  date = {2025-02-07},
  journaltitle = {Education Sciences},
  shortjournal = {Education Sciences},
  volume = {15},
  number = {2},
  pages = {199},
  issn = {2227-7102},
  doi = {10.3390/educsci15020199},
  url = {https://www.mdpi.com/2227-7102/15/2/199},
  urldate = {2025-09-25},
  abstract = {This study evaluates “I Learn with Prompt Engineering”, a self-paced, self-regulated elective course designed to equip university students with skills in prompt engineering to effectively utilize large language models (LLMs), foster self-directed learning, and enhance academic English proficiency through generative AI applications. By integrating prompt engineering concepts with generative AI tools, the course supports autonomous learning and addresses critical skill gaps in language proficiency and market-ready capabilities. The study also examines EnSmart, an AI-driven tool powered by GPT-4 and integrated into Canvas LMS, which automates academic test content generation and grading and delivers real-time, human-like feedback. Performance evaluation, structured questionnaires, and surveys were used to evaluate the course’s impact on prompting skills, academic English proficiency, and overall learning experiences. Results demonstrated significant improvements in prompt engineering skills, with accessible patterns like “Persona” proving highly effective, while advanced patterns such as “Flipped Interaction” posed challenges. Gains in academic English were most notable among students with lower initial proficiency, though engagement and practice time varied. Students valued EnSmart’s intuitive integration and grading accuracy but identified limitations in question diversity and adaptability. The high final success rate demonstrated that proper course design (taking into consideration Panadero’s four dimensions of self-regulated learning) can facilitate successful autonomous learning. The findings highlight generative AI’s potential to enhance autonomous learning and task automation, emphasizing the necessity of human oversight for ethical and effective implementation in education.},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/PIWKLB8A/Mzwri and Turcsányi-Szabo - 2025 - The Impact of Prompt Engineering and a Generative AI-Driven Tool on Autonomous Learning A Case Stud.pdf}
}

@article{Petronella2022,
  title = {Language Learning Strategies of High and Low Performing Second Language Learners: A Socio Cultural Perspective},
  shorttitle = {Language Learning Strategies of High and Low Performing Second Language Learners},
  author = {Petronella, Nondumiso Nompilo Machimana and Gerhard, Genis},
  date = {2022},
  journaltitle = {i-manager’s Journal on English Language Teaching},
  shortjournal = {JELT},
  volume = {12},
  number = {1},
  pages = {56},
  issn = {2231-3338, 2249-0752},
  doi = {10.26634/jelt.12.1.18343},
  url = {https://imanagerpublications.com/article/18343},
  urldate = {2025-09-25},
  abstract = {This paper explores and compares the language learning strategies of high and low performing second language (L2) learners participating in peer tutoring. The participating learners were grouped into high and low performing learners based on their scores in English second language. The classification of strategies by Griffiths into base, core and plus strategies was used to gain an in-depth understanding of the strategies used by the high and low performing second language learners. A descriptive research design was used to identify and interpret the strategies which the learners used in this study. Sociocultural theory was applied to frame and understand the results of this study. The results show that the learners used strategies at a high frequency and that low and high performing learners prefer different types of strategies. It is evident that high performing learners predominantly use cognitive and metacognitive strategies while low performing learners predominantly use social and memory strategies. These findings confirm Vygostky's sociocultural theory, which postulates that learning begins as a social activity but progresses into an internalised activity when the individual is able to self-regulate. The implication of these findings is that L2 learners need support through constructivist social interaction to enable them to transition from otherregulation and social regulation to self-regulation to enhance their L2 performance.},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/92K2NEG3/Petronella and Gerhard - 2022 - Language learning strategies of high and low performing second language learners a socio cultural p.pdf}
}

@article{Qian2025,
  title = {Prompt {{Engineering}} in {{Education}}: {{A Systematic Review}} of {{Approaches}} and {{Educational Applications}}},
  shorttitle = {Prompt {{Engineering}} in {{Education}}},
  author = {Qian, Yufeng},
  date = {2025-08-07},
  journaltitle = {Journal of Educational Computing Research},
  shortjournal = {Journal of Educational Computing Research},
  pages = {07356331251365189},
  issn = {0735-6331, 1541-4140},
  doi = {10.1177/07356331251365189},
  url = {https://journals.sagepub.com/doi/10.1177/07356331251365189},
  urldate = {2025-09-25},
  abstract = {The effectiveness of generative AI tools in education depends largely on prompt engineering—the practice of designing inputs and interactions that guide AI systems to produce relevant, high-quality outputs. This systematic literature review examines empirical studies published since the release of ChatGPT in late 2022, identifying two broad approaches of prompting strategies: technique-based, which targets specific learning goals, and process-based, which supports cognitive engagement and collaborative thinking with AI. The review identifies key educational applications of prompt engineering, notably in two overarching areas: critical skills development and the automation of educational functions. It also highlights emerging trends, such as the integration of multimodal AI and the growing influence of advanced AI reasoning capabilities. By mapping this evolving landscape, the findings provide a foundational understanding of prompt engineering as both a technical skill and a pedagogical strategy in AI-supported learning environments.},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/JEYK2Q3G/Qian - 2025 - Prompt Engineering in Education A Systematic Review of Approaches and Educational Applications.pdf}
}

@article{Saito2023,
  title = {Automated Assessment of Second Language Comprehensibility: {{Review}}, Training, Validation, and Generalization Studies},
  shorttitle = {Automated Assessment of Second Language Comprehensibility},
  author = {Saito, Kazuya and Macmillan, Konstantinos and Kachlicka, Magdalena and Kunihara, Takuya and Minematsu, Nobuaki},
  date = {2023-03},
  journaltitle = {Studies in Second Language Acquisition},
  shortjournal = {Stud Second Lang Acquis},
  volume = {45},
  number = {1},
  pages = {234--263},
  issn = {0272-2631, 1470-1545},
  doi = {10.1017/S0272263122000080},
  url = {https://www.cambridge.org/core/product/identifier/S0272263122000080/type/journal_article},
  urldate = {2025-06-26},
  abstract = {Abstract                            Whereas many scholars have emphasized the relative importance of               comprehensibility               as an ecologically valid goal for L2 speech training, testing, and development, eliciting listeners’ judgments is time-consuming. Following calls for research on more efficient L2 speech rating methods in applied linguistics, and growing attention toward using machine learning on spontaneous unscripted speech in speech engineering, the current study examined the possibility of establishing quick and reliable               automated               comprehensibility assessments. Orchestrating a set of phonological (maximum posterior probabilities and gaps between L1 and L2 speech), prosodic (pitch and intensity variation), and temporal measures (articulation rate, pause frequency), the regression model significantly predicted how naïve listeners intuitively judged low, mid, high, and nativelike comprehensibility among 100 L1 and L2 speakers’ picture descriptions. The strength of the correlation (               r               = .823 for machine vs. human ratings) was comparable to naïve listeners’ interrater agreement (               r               = .760 for humans vs. humans). The findings were successfully replicated when the model was applied to a new dataset of 45 L1 and L2 speakers (               r               = .827) and tested under a more freely constructed interview task condition (               r               = .809).},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/BKTNSQQR/Saito et al. - 2023 - Automated assessment of second language comprehensibility Review, training, validation, and general.pdf}
}

@inproceedings{Slavuj2015,
  title = {Intelligent Tutoring Systems for Language Learning},
  booktitle = {2015 38th {{International Convention}} on {{Information}} and {{Communication Technology}}, {{Electronics}} and {{Microelectronics}} ({{MIPRO}})},
  author = {Slavuj, V. and Kovačić, B. and Jugo, I.},
  date = {2015-05},
  pages = {814--819},
  location = {Opatija, Croatia},
  doi = {10.1109/MIPRO.2015.7160383},
  url = {https://ieeexplore.ieee.org/document/7160383/},
  urldate = {2025-06-27},
  abstract = {Intelligent tutoring systems (ITS) are able to provide a personalized approach to learning by assuming the role of a real teacher/expert who adapts and steers the learning process according to the specific needs of each learner. This is done by taking into account a number of learner features and deciding on the best action to follow at any point in the learning process. Within the field of computer assisted language learning (CALL), the “computer-as-a-tutor” modality has been widely accepted for some time now, although it has long been overshadowed by the “computer-as-a-tool” modality. This was mainly due to the observable lack of interactivity of language learning systems and the inability of technology to show “intelligence”. However, the development of artificial intelligence in general, and natural language processing, user modeling and ITSs in particular, gave impetus for the development of the field referred to as intelligent CALL (ICALL). The paper at hand outlines and briefly discusses the issues surrounding the development and use of ITSs for language learning, taking also into account the broader context of (I)CALL, and gives an overview of such systems already in use.},
  eventtitle = {2015 38th {{International Convention}} on {{Information}} and {{Communication Technology}}, {{Electronics}} and {{Microelectronics}} ({{MIPRO}})},
  keywords = {Adaptation models,Artificial intelligence,Computers,Context,Education,Software,Vocabulary},
  file = {/Users/francojc/Zotero/storage/R9UL9NC6/Slavuj et al. - 2015 - Intelligent tutoring systems for language learning.pdf}
}

@online{Tack2022,
  title = {The {{AI Teacher Test}}: {{Measuring}} the {{Pedagogical Ability}} of {{Blender}} and {{GPT-3}} in {{Educational Dialogues}}},
  shorttitle = {The {{AI Teacher Test}}},
  author = {Tack, Anaïs and Piech, Chris},
  date = {2022-05-16},
  eprint = {2205.07540},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.07540},
  url = {http://arxiv.org/abs/2205.07540},
  urldate = {2025-05-28},
  abstract = {How can we test whether state-of-the-art generative models, such as Blender and GPT-3, are good AI teachers, capable of replying to a student in an educational dialogue? Designing an AI teacher test is challenging: although evaluation methods are much-needed, there is no off-the-shelf solution to measuring pedagogical ability. This paper reports on a first attempt at an AI teacher test. We built a solution around the insight that you can run conversational agents in parallel to human teachers in real-world dialogues, simulate how different agents would respond to a student, and compare these counterpart responses in terms of three abilities: speak like a teacher, understand a student, help a student. Our method builds on the reliability of comparative judgments in education and uses a probabilistic model and Bayesian sampling to infer estimates of pedagogical ability. We find that, even though conversational agents (Blender in particular) perform well on conversational uptake, they are quantifiably worse than real teachers on several pedagogical dimensions, especially with regard to helpfulness (Blender: \{\textbackslash Delta\} ability = -0.75; GPT-3: \{\textbackslash Delta\} ability = -0.93).},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/francojc/Zotero/storage/28FNVQVY/Tack and Piech - 2022 - The AI Teacher Test Measuring the Pedagogical Ability of Blender and GPT-3 in Educational Dialogues.pdf;/Users/francojc/Zotero/storage/VAZAGW99/2205.html}
}

@article{VanLEHN2011,
  title = {The {{Relative Effectiveness}} of {{Human Tutoring}}, {{Intelligent Tutoring Systems}}, and {{Other Tutoring Systems}}},
  author = {VanLehn, Kurt},
  date = {2011-10},
  journaltitle = {Educational Psychologist},
  shortjournal = {Educational Psychologist},
  volume = {46},
  number = {4},
  pages = {197--221},
  issn = {0046-1520, 1532-6985},
  doi = {10.1080/00461520.2011.611369},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00461520.2011.611369},
  urldate = {2025-06-27},
  langid = {english},
  keywords = {category-psychology,important,mcp-research,review-needed,source-semantic_scholar},
  file = {/Users/francojc/Zotero/storage/73ITSIT4/VanLEHN - 2011 - The Relative Effectiveness of Human Tutoring, Intelligent Tutoring Systems, and Other Tutoring Syste.pdf}
}

@article{Wang2023a,
  title = {Examining the Applications of Intelligent Tutoring Systems in Real Educational Contexts: {{A}} Systematic Literature Review from the Social Experiment Perspective},
  shorttitle = {Examining the Applications of Intelligent Tutoring Systems in Real Educational Contexts},
  author = {Wang, Huanhuan and Tlili, Ahmed and Huang, Ronghuai and Cai, Zhenyu and Li, Min and Cheng, Zui and Yang, Dong and Li, Mengti and Zhu, Xixian and Fei, Cheng},
  date = {2023-07},
  journaltitle = {Education and Information Technologies},
  shortjournal = {Educ Inf Technol},
  volume = {28},
  number = {7},
  pages = {9113--9148},
  issn = {1360-2357, 1573-7608},
  doi = {10.1007/s10639-022-11555-x},
  url = {https://link.springer.com/10.1007/s10639-022-11555-x},
  urldate = {2025-10-25},
  abstract = {Intelligent Tutoring Systems (ITSs) have a great potential to effectively transform teaching and learning. As more efforts have been put on designing and developing ITSs and integrating them within learning and instruction, mixed types of results about the effectiveness of ITS have been reported. Therefore, it is necessary to investigate how ITSs work in real and natural educational contexts and the associated challenges of ITS application and evaluation. Through a systematic literature review method, this study analyzed 40 qualified studies that applied social experiment methods to examine the effectiveness of ITS during 2011–2022. The obtained results highlighted a complicated landscape regarding the effectiveness of ITS in real educational contexts. Specifically, there was an “intelligent” regional gap regarding the distribution of countries where ITS studies using social experiment methods were conducted. Compared to learning performance, relatively less attention was paid to investigating the impact of ITS on non-cognitive factors, process-oriented factors, and social outcomes, calling for more research in this regard. Considering the complexities and challenges existing in real educational fields, there was a lack of scientific rigor in terms of experimental design and data analysis in some of the studies. Based on these findings, suggestions for future study and implications were proposed.},
  langid = {english},
  file = {/Users/francojc/Zotero/storage/FW5WUJ95/Wang et al. - 2023 - Examining the applications of intelligent tutoring systems in real educational contexts A systemati.pdf}
}

@online{Wang2024,
  title = {Astute {{RAG}}: {{Overcoming Imperfect Retrieval Augmentation}} and {{Knowledge Conflicts}} for {{Large Language Models}}},
  shorttitle = {Astute {{RAG}}},
  author = {Wang, Fei and Wan, Xingchen and Sun, Ruoxi and Chen, Jiefeng and Arık, Sercan Ö},
  date = {2024-10-09},
  eprint = {2410.07176},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2410.07176},
  url = {http://arxiv.org/abs/2410.07176},
  urldate = {2025-04-14},
  abstract = {Retrieval-Augmented Generation (RAG), while effective in integrating external knowledge to address the limitations of large language models (LLMs), can be undermined by imperfect retrieval, which may introduce irrelevant, misleading, or even malicious information. Despite its importance, previous studies have rarely explored the behavior of RAG through joint analysis on how errors from imperfect retrieval attribute and propagate, and how potential conflicts arise between the LLMs' internal knowledge and external sources. We find that imperfect retrieval augmentation might be inevitable and quite harmful, through controlled analysis under realistic conditions. We identify the knowledge conflicts between LLM-internal and external knowledge from retrieval as a bottleneck to overcome in the post-retrieval stage of RAG. To render LLMs resilient to imperfect retrieval, we propose Astute RAG, a novel RAG approach that adaptively elicits essential information from LLMs' internal knowledge, iteratively consolidates internal and external knowledge with source-awareness, and finalizes the answer according to information reliability. Our experiments using Gemini and Claude demonstrate that Astute RAG significantly outperforms previous robustness-enhanced RAG methods. Notably, Astute RAG is the only approach that matches or exceeds the performance of LLMs without RAG under worst-case scenarios. Further analysis reveals that Astute RAG effectively resolves knowledge conflicts, improving the reliability and trustworthiness of RAG systems.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/francojc/Zotero/storage/3QHK776K/Wang et al. - 2024 - Astute RAG Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language M.pdf;/Users/francojc/Zotero/storage/YE22MAU3/2410.html}
}

@online{Wang2024a,
  title = {Large {{Language Models}} for {{Education}}: {{A Survey}} and {{Outlook}}},
  shorttitle = {Large {{Language Models}} for {{Education}}},
  author = {Wang, Shen and Xu, Tianlong and Li, Hang and Zhang, Chaoli and Liang, Joleen and Tang, Jiliang and Yu, Philip S. and Wen, Qingsong},
  date = {2024-04-01},
  eprint = {2403.18105},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.18105},
  url = {http://arxiv.org/abs/2403.18105},
  urldate = {2025-05-28},
  abstract = {The advent of Large Language Models (LLMs) has brought in a new era of possibilities in the realm of education. This survey paper summarizes the various technologies of LLMs in educational settings from multifaceted perspectives, encompassing student and teacher assistance, adaptive learning, and commercial tools. We systematically review the technological advancements in each perspective, organize related datasets and benchmarks, and identify the risks and challenges associated with deploying LLMs in education. Furthermore, we outline future research opportunities, highlighting the potential promising directions. Our survey aims to provide a comprehensive technological picture for educators, researchers, and policymakers to harness the power of LLMs to revolutionize educational practices and foster a more effective personalized learning environment.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/francojc/Zotero/storage/63364ZHD/Wang et al. - 2024 - Large Language Models for Education A Survey and Outlook.pdf;/Users/francojc/Zotero/storage/MUGV5DEY/2403.html}
}

@online{Wang2025,
  title = {Training {{Turn-by-Turn Verifiers}} for {{Dialogue Tutoring Agents}}: {{The Curious Case}} of {{LLMs}} as {{Your Coding Tutors}}},
  shorttitle = {Training {{Turn-by-Turn Verifiers}} for {{Dialogue Tutoring Agents}}},
  author = {Wang, Jian and Dai, Yinpei and Zhang, Yichi and Ma, Ziqiao and Li, Wenjie and Chai, Joyce},
  date = {2025-02-21},
  eprint = {2502.13311},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2502.13311},
  url = {http://arxiv.org/abs/2502.13311},
  urldate = {2025-04-14},
  abstract = {Intelligent tutoring agents powered by large language models (LLMs) have been increasingly explored to deliver personalized guidance in areas such as language learning and science education. However, their capabilities in guiding users to solve complex real-world tasks remain underexplored. To address this limitation, in this work, we focus on coding tutoring, a challenging problem that requires tutors to proactively guide students toward completing predefined coding tasks. We propose a novel agent workflow, Trace-and-Verify (TRAVER), which combines knowledge tracing to estimate a student's knowledge state and turn-by-turn verification to ensure effective guidance toward task completion. We introduce DICT, an automatic evaluation protocol that assesses tutor agents holistically using controlled student simulation and code generation tests. Extensive experiments reveal the challenges of coding tutoring and demonstrate that TRAVER achieves a significantly higher success rate. Although we use code tutoring as an example in this paper, our results and findings can be extended beyond coding, providing valuable insights into advancing tutoring agents for a variety of tasks.},
  pubstate = {prepublished},
  version = {2},
  keywords = {category-cs.ai,category-cs.cl,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,important,mcp-research,review-needed,source-arxiv},
  file = {/Users/francojc/Zotero/storage/S58HKWAM/Wang et al. - 2025 - Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents The Curious Case of LLMs as Your Codin.pdf;/Users/francojc/Zotero/storage/AMEDFCK3/2502.html}
}

@article{Wang2025a,
  title = {The Effect of {{ChatGPT}} on Students’ Learning Performance, Learning Perception, and Higher-Order Thinking: Insights from a Meta-Analysis},
  shorttitle = {The Effect of {{ChatGPT}} on Students’ Learning Performance, Learning Perception, and Higher-Order Thinking},
  author = {Wang, Jin and Fan, Wenxiang},
  date = {2025-05-06},
  journaltitle = {Humanities and Social Sciences Communications},
  shortjournal = {Humanit Soc Sci Commun},
  volume = {12},
  number = {1},
  pages = {1--21},
  publisher = {Palgrave},
  issn = {2662-9992},
  doi = {10.1057/s41599-025-04787-y},
  url = {https://www.nature.com/articles/s41599-025-04787-y},
  urldate = {2025-05-15},
  abstract = {As a new type of artificial intelligence, ChatGPT is becoming widely used in learning. However, academic consensus regarding its efficacy remains elusive. This study aimed to assess the effectiveness of ChatGPT in improving students’ learning performance, learning perception, and higher-order thinking through a meta-analysis of 51 research studies published between November 2022 and February 2025. The results indicate that ChatGPT has a large positive impact on improving learning performance (g\,=\,0.867) and a moderately positive impact on enhancing learning perception (g\,=\,0.456) and fostering higher-order thinking (g\,=\,0.457). The impact of ChatGPT on learning performance was moderated by type of course (QB\,=\,64.249, P\,{$<$}\,0.001), learning model (QB\,=\,76.220, P\,{$<$}\,0.001), and duration (QB\,=\,55.998, P\,{$<$}\,0.001); its effect on learning perception was moderated by duration (QB\,=\,19.839, P\,{$<$}\,0.001); and its influence on the development of higher-order thinking was moderated by type of course (QB\,=\,7.811, P\,{$<$}\,0.05) and the role played by ChatGPT (QB\,=\,4.872, P\,{$<$}\,0.05). This study suggests that: (1) appropriate learning scaffolds or educational frameworks (e.g., Bloom’s taxonomy) should be provided when using ChatGPT to develop students’ higher-order thinking; (2) the broad use of ChatGPT at various grade levels and in different types of courses should be encouraged to support diverse learning needs; (3) ChatGPT should be actively integrated into different learning modes to enhance student learning, especially in problem-based learning; (4) continuous use of ChatGPT should be ensured to support student learning, with a recommended duration of 4–8 weeks for more stable effects; (5) ChatGPT should be flexibly integrated into teaching as an intelligent tutor, learning partner, and educational tool. Finally, due to the limited sample size for learning perception and higher-order thinking, and the moderately positive effect, future studies with expanded scope should further explore how to use ChatGPT more effectively to cultivate students’ learning perception and higher-order thinking.},
  langid = {english},
  keywords = {Education,learning,llms,Science,teaching,technology and society},
  file = {/Users/francojc/Zotero/storage/I6RCY5XP/Wang and Fan - 2025 - The effect of ChatGPT on students’ learning performance, learning perception, and higher-order think.pdf}
}

@article{Xing2025,
  title = {The {{Use}} of {{Large Language Models}} in {{Education}}},
  author = {Xing, Wanli and Nixon, Nia and Crossley, Scott and Denny, Paul and Lan, Andrew and Stamper, John and Yu, Zhou},
  date = {2025-02-04},
  journaltitle = {International Journal of Artificial Intelligence in Education},
  shortjournal = {Int J Artif Intell Educ},
  issn = {1560-4306},
  doi = {10.1007/s40593-025-00457-x},
  url = {https://doi.org/10.1007/s40593-025-00457-x},
  urldate = {2025-02-10},
  langid = {english},
  keywords = {education,llm},
  file = {/Users/francojc/Zotero/storage/MYB3KTH9/Xing et al. - 2025 - The Use of Large Language Models in Education.pdf}
}

@online{Ye2025,
  title = {Position: {{LLMs Can}} Be {{Good Tutors}} in {{Foreign Language Education}}},
  shorttitle = {Position},
  author = {Ye, Jingheng and Wang, Shen and Zou, Deqing and Yan, Yibo and Wang, Kun and Zheng, Hai-Tao and Xu, Zenglin and King, Irwin and Yu, Philip S. and Wen, Qingsong},
  date = {2025-02-08},
  eprint = {2502.05467},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2502.05467},
  url = {http://arxiv.org/abs/2502.05467},
  urldate = {2025-04-29},
  abstract = {While recent efforts have begun integrating large language models (LLMs) into foreign language education (FLE), they often rely on traditional approaches to learning tasks without fully embracing educational methodologies, thus lacking adaptability to language learning. To address this gap, we argue that LLMs have the potential to serve as effective tutors in FLE. Specifically, LLMs can play three critical roles: (1) as data enhancers, improving the creation of learning materials or serving as student simulations; (2) as task predictors, serving as learner assessment or optimizing learning pathway; and (3) as agents, enabling personalized and inclusive education. We encourage interdisciplinary research to explore these roles, fostering innovation while addressing challenges and risks, ultimately advancing FLE through the thoughtful integration of LLMs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/francojc/Zotero/storage/PRFUVNIS/Ye et al. - 2025 - Position LLMs Can be Good Tutors in Foreign Language Education.pdf;/Users/francojc/Zotero/storage/V2ZVWAG8/2502.html}
}
